import argparse
import os
import csv
from pathlib import Path
from typing import List, Tuple
import time
from datetime import datetime

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel


def load_prompts_from_txt(file_path: str) -> List[str]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã –∏–∑ TXT —Ñ–∞–π–ª–∞"""
    prompts = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#'):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                prompts.append(line)
    return prompts


def load_prompts_from_csv(file_path: str, column_name: str = 'prompt') -> List[str]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã –∏–∑ CSV —Ñ–∞–π–ª–∞"""
    prompts = []
    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        if column_name not in reader.fieldnames:
            available = ', '.join(reader.fieldnames)
            raise ValueError(f"–ö–æ–ª–æ–Ω–∫–∞ '{column_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available}")
        
        for row in reader:
            if row[column_name] and row[column_name].strip():
                prompts.append(row[column_name].strip())
    return prompts


def load_prompts(args) -> List[str]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–∞–π–ª —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏
    if args.prompts_file:
        file_path = Path(args.prompts_file)
        
        if not file_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.prompts_file}")
        
        if file_path.suffix.lower() == '.txt':
            print(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ TXT —Ñ–∞–π–ª–∞: {args.prompts_file}")
            return load_prompts_from_txt(args.prompts_file)
        
        elif file_path.suffix.lower() == '.csv':
            print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ CSV —Ñ–∞–π–ª–∞: {args.prompts_file}")
            return load_prompts_from_csv(args.prompts_file, args.csv_column)
        
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_path.suffix}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ .txt –∏–ª–∏ .csv")
    
    # –ï—Å–ª–∏ –ø—Ä–æ–º–ø—Ç—ã –ø–µ—Ä–µ–¥–∞–Ω—ã –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É
    elif args.prompts:
        print(f"üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏")
        return args.prompts
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ D&D
    else:
        print("‚ö†Ô∏è  –§–∞–π–ª —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –ø–æ D&D 3.5")
        return [
            "How does Bless work in D&D 3.5?",
            "I attack the zombie with my longsword",
            "Can I cast Fireball as a 5th level wizard?",
            "What's the DC for a Perception check?",
            "How much damage does a greatsword do on a critical hit?"
        ]


def load_models(model_name: str, lora_path: str = None) -> Tuple[AutoModelForCausalLM, AutoModelForCausalLM]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑–æ–≤—É—é –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª–∏
    
    Returns:
        tuple: (base_model, fine_tuned_model)
    """
    print(f"ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {model_name}")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
    base_model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype="auto",
        device_map="auto",
    )
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (—Å LoRA)
    if lora_path and os.path.exists(lora_path):
        print(f"üîó –ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞: {lora_path}")
        fine_tuned_model = PeftModel.from_pretrained(base_model, lora_path)
        print("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        return base_model, fine_tuned_model, tokenizer
    else:
        print("‚ö†Ô∏è  LoRA –∞–¥–∞–ø—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å")
        return base_model, base_model, tokenizer


def generate_response(model, tokenizer, prompt: str, gen_args: dict) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"""
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            **gen_args
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã
    if response.startswith(prompt):
        response = response[len(prompt):].strip()
    
    return response


def compare_models(base_model, fine_tuned_model, tokenizer, prompts: List[str], 
                   gen_args: dict, output_file: str = None):
    """–°—Ä–∞–≤–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç—ã –±–∞–∑–æ–≤–æ–π –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–µ–π"""
    
    results = []
    total_base_time = 0
    total_finetuned_time = 0
    
    print("=" * 100)
    print(f"{'üìä –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô':^100}")
    print("=" * 100)
    print(f"{'–ü–ê–†–ê–ú–ï–¢–†–´ –ì–ï–ù–ï–†–ê–¶–ò–ò:':<30} max_tokens={gen_args['max_new_tokens']}, "
          f"temp={gen_args['temperature']}, top_p={gen_args['top_p']}")
    print("=" * 100)
    
    for i, prompt in enumerate(prompts, 1):
        print(f"\n{'üöÄ –ü–†–û–ú–ü–¢ ' + str(i) + '/' + str(len(prompts)) + ' ':‚îÄ^100}")
        print(f"üìù: {prompt}")
        print("-" * 100)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        print(f"{'üîµ –ë–ê–ó–û–í–ê–Ø –ú–û–î–ï–õ–¨':<50}{'üü¢ –î–û–û–ë–£–ß–ï–ù–ù–ê–Ø –ú–û–î–ï–õ–¨':<50}")
        print("-" * 100)
        
        start_time = time.time()
        base_response = generate_response(base_model, tokenizer, prompt, gen_args)
        base_time = time.time() - start_time
        total_base_time += base_time
        
        start_time = time.time()
        finetuned_response = generate_response(fine_tuned_model, tokenizer, prompt, gen_args)
        finetuned_time = time.time() - start_time
        total_finetuned_time += finetuned_time
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
        base_lines = base_response.split('\n')
        finetuned_lines = finetuned_response.split('\n')
        max_lines = max(len(base_lines), len(finetuned_lines))
        
        # –í—ã–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        for j in range(max_lines):
            base_line = base_lines[j] if j < len(base_lines) else ""
            finetuned_line = finetuned_lines[j] if j < len(finetuned_lines) else ""
            
            # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if len(base_line) > 45:
                base_line = base_line[:42] + "..."
            if len(finetuned_line) > 45:
                finetuned_line = finetuned_line[:42] + "..."
            
            print(f"{base_line:<50}{finetuned_line:<50}")
        
        print(f"{f'‚è±Ô∏è {base_time:.2f}s':<50}{f'‚è±Ô∏è {finetuned_time:.2f}s':<50}")
        print("-" * 100)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results.append({
            'prompt': prompt,
            'base_response': base_response,
            'finetuned_response': finetuned_response,
            'base_time': base_time,
            'finetuned_time': finetuned_time
        })
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 100)
    print(f"{'üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê':^100}")
    print("=" * 100)
    print(f"{'–ú–ï–¢–†–ò–ö–ê':<30} {'–ë–ê–ó–û–í–ê–Ø':<20} {'–î–û–û–ë–£–ß–ï–ù–ù–ê–Ø':<20} {'–†–ê–ó–ù–ò–¶–ê':<20}")
    print("-" * 100)
    print(f"{'–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞':<30} {total_base_time/len(prompts):<20.3f}s "
          f"{total_finetuned_time/len(prompts):<20.3f}s "
          f"{(total_finetuned_time - total_base_time)/len(prompts):<+20.3f}s")
    print(f"{'–û–±—â–µ–µ –≤—Ä–µ–º—è':<30} {total_base_time:<20.3f}s {total_finetuned_time:<20.3f}s "
          f"{total_finetuned_time - total_base_time:<+20.3f}s")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω –æ—Ç–≤–µ—Ç–æ–≤
    total_base_chars = sum(len(r['base_response']) for r in results)
    total_finetuned_chars = sum(len(r['finetuned_response']) for r in results)
    print(f"{'–°—É–º–º–∞—Ä–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–æ–≤':<30} {total_base_chars:<20} chars "
          f"{total_finetuned_chars:<20} chars "
          f"{total_finetuned_chars - total_base_chars:<+20} chars")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª
    if output_file:
        save_results(results, output_file, gen_args)
    
    return results


def save_results(results: List[dict], output_file: str, gen_args: dict):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª"""
    import json
    from datetime import datetime
    
    output_data = {
        'timestamp': datetime.now().isoformat(),
        'generation_parameters': gen_args,
        'total_prompts': len(results),
        'results': results
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–µ–π',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python test_comparison.py --prompts_file prompts.txt
  python test_comparison.py --prompts "How does Bless work?" "I attack the orc"
  python test_comparison.py --lora_path ./my-lora-model --csv_column instruction
        """
    )
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--model_name', type=str, default="Qwen/Qwen2.5-1.5B",
                       help='–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –≤ HF (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: Qwen/Qwen2.5-1.5B)')
    parser.add_argument('--lora_path', type=str, default="./my-lora-model",
                       help='–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∞–¥–∞–ø—Ç–µ—Ä–æ–º LoRA (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./my-lora-model)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–æ–≤
    parser.add_argument('--prompts_file', type=str, 
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏ (.txt –∏–ª–∏ .csv)')
    parser.add_argument('--prompts', type=str, nargs='+',
                       help='–°–ø–∏—Å–æ–∫ –ø—Ä–æ–º–ø—Ç–æ–≤ –ø—Ä—è–º–æ –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ')
    parser.add_argument('--csv_column', type=str, default='prompt',
                       help='–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ CSV —Ñ–∞–π–ª–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: prompt)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    parser.add_argument('--max_new_tokens', type=int, default=150,
                       help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 150)')
    parser.add_argument('--temperature', type=float, default=0.7,
                       help='–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.7)')
    parser.add_argument('--top_p', type=float, default=0.9,
                       help='Top-p sampling –ø–∞—Ä–∞–º–µ—Ç—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.9)')
    parser.add_argument('--top_k', type=int, default=50,
                       help='Top-k sampling –ø–∞—Ä–∞–º–µ—Ç—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 50)')
    parser.add_argument('--repetition_penalty', type=float, default=1.2,
                       help='–®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1.2)')
    parser.add_argument('--num_return_sequences', type=int, default=1,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1)')
    parser.add_argument('--seed', type=int, default=42,
                       help='Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 42)')
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--output_file', type=str, default="comparison_results.json",
                       help='–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: comparison_results.json)')
    parser.add_argument('--no_compare', action='store_true',
                       help='–ù–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å, –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å')
    
    args = parser.parse_args()
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    if args.seed is not None:
        import numpy as np
        import random
        
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(args.seed)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã
    try:
        prompts = load_prompts(args)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–æ–≤: {e}")
        return
    
    if not prompts:
        print("‚ùå –ù–µ—Ç –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return
    
    print(f"üéØ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–º–ø—Ç–æ–≤: {len(prompts)}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
    try:
        base_model, fine_tuned_model, tokenizer = load_models(args.model_name, args.lora_path)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        return
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    gen_args = {
        'max_new_tokens': args.max_new_tokens,
        'temperature': args.temperature,
        'top_p': args.top_p,
        'top_k': args.top_k,
        'repetition_penalty': args.repetition_penalty,
        'num_return_sequences': args.num_return_sequences,
        'do_sample': True if args.temperature > 0 else False,
        'pad_token_id': tokenizer.pad_token_id or tokenizer.eos_token_id,
    }
    
    if args.no_compare:
        # –ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å–∫–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        print("\n" + "=" * 100)
        print(f"{'üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –î–û–û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò':^100}")
        print("=" * 100)
        
        for i, prompt in enumerate(prompts, 1):
            print(f"\nüìù –ü—Ä–æ–º–ø—Ç {i}/{len(prompts)}: {prompt}")
            print("-" * 100)
            
            response = generate_response(fine_tuned_model, tokenizer, prompt, gen_args)
            print(f"ü§ñ –û—Ç–≤–µ—Ç: {response}")
            print("=" * 100)
    else:
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏
        results = compare_models(
            base_model=base_model,
            fine_tuned_model=fine_tuned_model,
            tokenizer=tokenizer,
            prompts=prompts,
            gen_args=gen_args,
            output_file=args.output_file
        )
        
        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        print("\n" + "=" * 100)
        print(f"{'üìã –ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó':^100}")
        print("=" * 100)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–∏—è –≤ –æ—Ç–≤–µ—Ç–∞—Ö
        improvements = 0
        same = 0
        worse = 0
        
        for result in results:
            base_len = len(result['base_response'])
            finetuned_len = len(result['finetuned_response'])
            
            # –ü—Ä–æ—Å—Ç–æ–π —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            dnd_keywords = ['spell', 'attack', 'damage', 'DC', 'roll', 'check', 'level', 'save']
            base_dnd_count = sum(1 for kw in dnd_keywords if kw in result['base_response'].lower())
            finetuned_dnd_count = sum(1 for kw in dnd_keywords if kw in result['finetuned_response'].lower())
            
            if finetuned_dnd_count > base_dnd_count:
                improvements += 1
            elif finetuned_dnd_count == base_dnd_count:
                same += 1
            else:
                worse += 1
        
        print(f"\nüìä –ö–ê–ß–ï–°–¢–í–û –û–¢–í–ï–¢–û–í (–ø–æ –Ω–∞–ª–∏—á–∏—é D&D —Ç–µ—Ä–º–∏–Ω–æ–≤):")
        print(f"   üü¢ –£–ª—É—á—à–µ–Ω–æ: {improvements}/{len(results)} ({improvements/len(results)*100:.1f}%)")
        print(f"   ‚ö™ –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {same}/{len(results)} ({same/len(results)*100:.1f}%)")
        print(f"   üî¥ –£—Ö—É–¥—à–µ–Ω–æ: {worse}/{len(results)} ({worse/len(results)*100:.1f}%)")
        
        # –ü—Ä–∏–º–µ—Ä—ã –ª—É—á—à–∏—Ö —É–ª—É—á—à–µ–Ω–∏–π
        if improvements > 0:
            print(f"\nüéØ –ü—Ä–∏–º–µ—Ä—ã —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤:")
            for i, result in enumerate(results[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                print(f"   {i+1}. –ü—Ä–æ–º–ø—Ç: {result['prompt'][:50]}...")
                print(f"      –ë–∞–∑–æ–≤–∞—è: {result['base_response'][:60]}...")
                print(f"      –î–æ–æ–±—É—á–µ–Ω–Ω–∞—è: {result['finetuned_response'][:60]}...")
                print()


if __name__ == "__main__":
    main()
