# üßô‚Äç‚ôÇÔ∏è D&D 3.5 –ò–ò-–ü–æ–º–æ—â–Ω–∏–∫ –ú–∞—Å—Ç–µ—Ä–∞ –ü–æ–¥–∑–µ–º–µ–ª–∏–π

–î–æ–æ–±—É—á–µ–Ω–∏–µ Qwen2.5-1.5B —Å –ø–æ–º–æ—â—å—é LoRA –¥–ª—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ –º–µ—Ö–∞–Ω–∏–∫–∞–º –∏–≥—Ä—ã Dungeons & Dragons 3.5 Edition.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/dnd-ai-assistant/blob/main/train_debug_2.py)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-blue)](https://huggingface.co/datasets/m0no1/dnd-mechanics-dataset)
[![Python 3.9+](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
- [–û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞](#-–æ–±–∑–æ—Ä-–ø—Ä–æ–µ–∫—Ç–∞)
- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏](#-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-–º–æ–¥–µ–ª–∏)
- [–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è](#-–¥–∞–Ω–Ω—ã–µ-–¥–ª—è-–æ–±—É—á–µ–Ω–∏—è)
- [–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è](#-–ø—Ä–æ—Ü–µ—Å—Å-–æ–±—É—á–µ–Ω–∏—è)
- [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã](#-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
- [–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](#-–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç)
- [–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#-–ø—Ä–∏–º–µ—Ä—ã-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
- [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞](#-—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–ø—Ä–æ–µ–∫—Ç–∞)
- [–£—Å—Ç–∞–Ω–æ–≤–∫–∞](#-—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
- [–û–±—É—á–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏](#-–æ–±—É—á–µ–Ω–∏–µ-—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π-–º–æ–¥–µ–ª–∏)
- [–õ–∏—Ü–µ–Ω–∑–∏—è](#-–ª–∏—Ü–µ–Ω–∑–∏—è)

## üéØ –û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç **–¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Qwen2.5-1.5B** —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º **LoRA (Low-Rank Adaptation)** –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ò–ò-–ø–æ–º–æ—â–Ω–∏–∫–∞, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–µ–≥–æ—Å—è –Ω–∞ **–ø—Ä–∞–≤–∏–ª–∞—Ö Dungeons & Dragons 3.5 Edition**.

–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏–≥—Ä–æ–≤—ã–º –º–µ—Ö–∞–Ω–∏–∫–∞–º, –≤–∫–ª—é—á–∞—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –±–æ–µ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–∫–ª–∏–Ω–∞–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–≤—ã–∫–æ–≤ –∏ —Ä–∞—Å—á–µ—Ç—ã –±—Ä–æ—Å–∫–æ–≤ –∫–æ—Å—Ç–µ–π.

### üöÄ –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
- ‚úÖ **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ D&D 3.5**: –û–±—É—á–µ–Ω–∞ –Ω–∞ 40,365+ –ø–∞—Ä–∞—Ö –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º –∏–≥—Ä—ã
- ‚úÖ **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ**: –î–æ–±–∞–≤–ª–µ–Ω–æ –≤—Å–µ–≥–æ 1.18% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é LoRA (18.5M –∏–∑ 1.56B)
- ‚úÖ **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—â–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π**: –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —è–∑—ã–∫–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏
- ‚úÖ **–î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å TensorBoard
- ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**: –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è

### üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏
1. **–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å** –¥–ª—è —É–∑–∫–æ—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–≥—Ä–æ–≤–æ–π –º–µ—Ö–∞–Ω–∏–∫–∏
2. **–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–µ–∑–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç** –¥–ª—è –º–∞—Å—Ç–µ—Ä–æ–≤ –∏–≥—Ä (Dungeon Masters) –∏ –∏–≥—Ä–æ–∫–æ–≤
3. **–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å LoRA** –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π
4. **–û–±–µ—Å–ø–µ—á–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å** —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏

### –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
- **–ú–æ–¥–µ–ª—å**: `Qwen/Qwen2.5-1.5B`
- **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**: 1.5 –º–∏–ª–ª–∏–∞—Ä–¥–∞
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å —Å causal language modeling
- **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ**: 32,768 —Ç–æ–∫–µ–Ω–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 512 –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
- **–Ø–∑—ã–∫–∏**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤
- **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å —Ö–æ—Ä–æ—à–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA
```python
LoraConfig(
    r=16,                    # –†–∞–Ω–≥ LoRA
    lora_alpha=64,           # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
    lora_dropout=0.2,        # Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    target_modules=[         # –ú–æ–¥—É–ª–∏ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è LoRA
        'q_proj', 'k_proj', 'v_proj', 'o_proj',
        'gate_proj', 'up_proj', 'down_proj'
    ],
    bias="none",
    task_type="CAUSAL_LM"
)
```

**–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –î–æ–±–∞–≤–ª–µ–Ω–æ –≤—Å–µ–≥–æ **18,464,768 –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** (1.18% –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞).

## üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

### –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞
- **–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞**: Hugging Face Datasets
- **–ù–∞–∑–≤–∞–Ω–∏–µ**: `m0no1/dnd-mechanics-dataset`
- **–†–∞–∑–º–µ—Ä**: 40,365 –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ 4,614 –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è)
- **–¶–µ–ª—å**: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–æ–ª–∏ –∑–Ω–∞—é—â–µ–≥–æ –ú–∞—Å—Ç–µ—Ä–∞ –ü–æ–¥–∑–µ–º–µ–ª–∏–π D&D 3.5

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
–ö–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ñ–æ—Ä–º–∞—Ç:
```json
{
    "instruction": "I attack the zombie",
    "input": "",
    "output": "Attack: [1d20+5] = 20! Critical threat! Confirm: [1d20+5] = 21. Damage: [1d8+1d8+3] = 8 slashing."
}
```

### –¢–µ–º—ã, –æ—Ö–≤–∞—Ç—ã–≤–∞–µ–º—ã–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–º
- üé≤ **–ë–æ–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è**: –ê—Ç–∞–∫–∏, —É—Ä–æ–Ω, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ø–∞–¥–∞–Ω–∏—è
- üîÆ **–ó–∞–∫–ª–∏–Ω–∞–Ω–∏—è**: –≠—Ñ—Ñ–µ–∫—Ç—ã, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- üìä **–ü—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–≤—ã–∫–æ–≤**: –ë—Ä–æ—Å–æ–∫ –∫–æ—Å—Ç–µ–π, –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ—Ä–æ–∫ (DC)
- ‚öîÔ∏è **–ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π**: –£—Ä–æ–≤–Ω–∏, –∫–ª–∞—Å—Å—ã, —É–º–µ–Ω–∏—è
- üìñ **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–∞–≤–∏–ª**: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∫, —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å–ø–æ—Ä–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π

### –ü—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
```json
{
    "instruction": "Can I cast Reverse Gravity?",
    "input": "",
    "output": "No, Reverse Gravity requires wizard level 13 (you're level 12)."
}

{
    "instruction": "I copy Create Water to my spellbook",
    "input": "",
    "output": "Costs 100 gp in materials. Takes 1 hours. Make Spellcraft DC 16."
}

{
    "instruction": "I make a Perception check for traps",
    "input": "",
    "output": "Roll: [1d20+8] = 15. You don't find any traps in this area."
}
```

## üöÄ –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è

### –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
```yaml
# –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
batch_size: 4                 # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
epochs: 3                     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
learning_rate: 2e-4           # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
max_length: 512               # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
warmup_steps: 100             # –®–∞–≥–æ–≤ –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞
gradient_accumulation: 1      # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
optimizer: AdamW              # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
scheduler: Cosine with warmup # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ learning rate

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã LoRA
lora_rank: 16                 # –†–∞–Ω–∫ LoRA
lora_alpha: 64                # –ê–ª—å—Ñ–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
lora_dropout: 0.2             # Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
```

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| –í—Å–µ–≥–æ —à–∞–≥–æ–≤ | 1,089 |
| –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | ~6 –º–∏–Ω—É—Ç (T4 GPU) |
| –ù–∞—á–∞–ª—å–Ω—ã–π loss | 3.281 |
| –§–∏–Ω–∞–ª—å–Ω—ã–π loss | 0.958 |
| –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π loss | 0.851 |
| –°–∫–æ—Ä–æ—Å—Ç—å | 2.45 –∏—Ç–µ—Ä–∞—Ü–∏–π/—Å–µ–∫ |

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
–ü—Ä–æ–µ–∫—Ç –≤–∫–ª—é—á–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å:
- **Real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** –ø–æ—Ç–µ—Ä—å –∏ learning rate
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏** –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
- **TensorBoard –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è** –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
- **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π** –∏ –º–µ—Ç—Ä–∏–∫ –≤ JSON/CSV
- **–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö** –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—É—á–µ–Ω–∏—è

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
2. **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç**: –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
3. **–ü–æ–ª–æ–≤–∏–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (FP16)**: –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ GPU
4. **–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ —à–∞–≥–∞–º**: –†–µ–≥—É–ª—è—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö
5. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫**: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏

## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- **–°–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å**: –° 3.28 –¥–æ 0.96 –∑–∞ –ø–µ—Ä–≤—ã–µ 100 —à–∞–≥–æ–≤
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**: –í—Å–µ–≥–æ 1.18% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç—Ä–µ–±—É—é—Ç –æ–±—É—á–µ–Ω–∏—è
- **–ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏**: ~6GB VRAM –Ω–∞ T4 GPU
- **–°–∫–æ—Ä–æ—Å—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏**: –ë—ã—Å—Ç—Ä–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≤ —Ü–µ–ª–µ–≤–æ–π –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏

### –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã

#### –ü—Ä–∏–º–µ—Ä 1: –ë–æ–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
**–ü—Ä–æ–º–ø—Ç**: `"I attack the orc with my longsword"`

| –ú–æ–¥–µ–ª—å | –û—Ç–≤–µ—Ç | –ö–∞—á–µ—Å—Ç–≤–æ |
|--------|-------|----------|
| **–ë–∞–∑–æ–≤–∞—è** | "You swing your sword at the orc, hoping to hit it..." | –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –±–µ–∑ –∏–≥—Ä–æ–≤–æ–π –º–µ—Ö–∞–Ω–∏–∫–∏ |
| **–î–æ–æ–±—É—á–µ–Ω–Ω–∞—è** | "Make an attack roll: [1d20+5]. If it hits, deal [1d8+3] slashing damage. Critical on 19-20 for x2 damage." | ‚úÖ –¢–æ—á–Ω–æ —Å–ª–µ–¥—É–µ—Ç –ø—Ä–∞–≤–∏–ª–∞–º D&D 3.5 |

#### –ü—Ä–∏–º–µ—Ä 2: –ó–∞–∫–ª–∏–Ω–∞–Ω–∏—è
**–ü—Ä–æ–º–ø—Ç**: `"How does Bless work in combat?"`

| –ú–æ–¥–µ–ª—å | –û—Ç–≤–µ—Ç | –ö–∞—á–µ—Å—Ç–≤–æ |
|--------|-------|----------|
| **–ë–∞–∑–æ–≤–∞—è** | "Bless is a religious ceremony that..." | –†–µ–ª–∏–≥–∏–æ–∑–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –∏–≥—Ä–æ–π |
| **–î–æ–æ–±—É—á–µ–Ω–Ω–∞—è** | "Bless: Enchantment (Compulsion) [Mind-Affecting]. Range: 50 ft. Targets: allies. Effect: +1 morale bonus on attack rolls and saves vs fear for 3 minutes." | ‚úÖ –î–µ—Ç–∞–ª—å–Ω–æ–µ –∏–≥—Ä–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ |

#### –ü—Ä–∏–º–µ—Ä 3: –ü—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–≤—ã–∫–æ–≤
**–ü—Ä–æ–º–ø—Ç**: `"I try to climb the castle wall"`

| –ú–æ–¥–µ–ª—å | –û—Ç–≤–µ—Ç | –ö–∞—á–µ—Å—Ç–≤–æ |
|--------|-------|----------|
| **–ë–∞–∑–æ–≤–∞—è** | "You attempt to scale the wall carefully..." | –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç |
| **–î–æ–æ–±—É—á–µ–Ω–Ω–∞—è** | "Make a Climb check: DC 15 for rough stone. Roll: [1d20+3]. With armor check penalty of -4, your total is..." | ‚úÖ –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∞—è –∏–≥—Ä–æ–≤–∞—è –º–µ—Ö–∞–Ω–∏–∫–∞ |

## 3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
```python
# test.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

base_model = "Qwen/Qwen2.5-1.5B"
lora_path = "./my-lora-model"   # –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∞–¥–∞–ø—Ç–µ—Ä–æ–º LoRA

tokenizer = AutoTokenizer.from_pretrained(base_model)

model = AutoModelForCausalLM.from_pretrained(
    base_model,
    torch_dtype="auto",
    device_map="auto",
)

model = PeftModel.from_pretrained(model, lora_path)

prompt = "How does Bless work in D&D 3.5?"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=200)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### 4. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç
```bash
python chatting.py \
  --model_name "Qwen/Qwen2.5-1.5B" \
  --model_dir "./my-lora-model" \
  --test_seed 43536
```

## üí¨ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ö–æ–º–∞–Ω–¥–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
```bash
# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
python train_debug_2.py \
  --model_name "Qwen/Qwen2.5-1.5B" \
  --data_path "./dnd_dataset.jsonl" \
  --output_dir "./my-lora-model" \
  --use_lora \
  --lora_r 16 \
  --num_train_epochs 3 \
  --learning_rate 2e-4

# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
python chatting.py \
  --model_name "Qwen/Qwen2.5-1.5B" \
  --model_dir "./my-lora-model"

# –ü–∞–∫–µ—Ç–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
python test.py
```

### Google Colab

–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Colab:
```bash
!python train_debug_2.py \
  --model_name "Qwen/Qwen2.5-1.5B" \
  --data_path "/content/dnd_dataset.jsonl" \
  --output_dir "/content/my-lora-model" \
  --use_lora \
  --lora_r 16 \
  --per_device_train_batch_size 4 \
  --num_train_epochs 3 \
  --learning_rate 2e-4 \
  --save_to_drive
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
```
dnd-ai-assistant/
‚îú‚îÄ‚îÄ train_debug_2.py          # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ test.py                   # –°–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ chatting.py               # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç —Å –º–æ–¥–µ–ª—å—é
‚îú‚îÄ‚îÄ requirements.txt          # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îú‚îÄ‚îÄ README.md                 # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ my-lora-model/        # –û–±—É—á–µ–Ω–Ω—ã–µ –∞–¥–∞–ø—Ç–µ—Ä—ã LoRA
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adapter_model.bin
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adapter_config.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îî‚îÄ‚îÄ base_models/          # –ö–µ—à –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ dnd_dataset.jsonl     # –ü—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îî‚îÄ‚îÄ test_prompts.txt      # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
‚îú‚îÄ‚îÄ logs/                     # –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ experiment_YYYYMMDD_HHMMSS/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_logs.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_progress_*.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ final_training_summary.png
‚îî‚îÄ‚îÄ examples/                 # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    ‚îú‚îÄ‚îÄ combat_resolution.py
    ‚îú‚îÄ‚îÄ spell_queries.py
    ‚îî‚îÄ‚îÄ skill_checks.py
```

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
```txt
torch>=2.0.0
transformers>=4.35.0
datasets>=2.14.0
peft>=0.7.0
accelerate>=0.24.0
tensorboard>=2.14.0
matplotlib>=3.7.0
pandas>=2.0.0
numpy>=1.24.0
```

### –ü–æ—à–∞–≥–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
%%bash
python -m venv llm_env
source llm_env/bin/activate
pip install -r /content/LLM_LoRA_training/requirements.txt

# 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch (–≤—ã–±–µ—Ä–∏—Ç–µ –≤–µ—Ä—Å–∏—é –¥–ª—è –≤–∞—à–µ–π CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø—Ä–æ–µ–∫—Ç–∞
pip install -r requirements.txt

# 4. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
python -c "from datasets import load_dataset; ds = load_dataset('m0no1/dnd-mechanics-dataset')"
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
```python
# test_installation.py
import torch
print(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
print(f"CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")

import transformers
print(f"Transformers –≤–µ—Ä—Å–∏—è: {transformers.__version__}")

import peft
print(f"PEFT –≤–µ—Ä—Å–∏—è: {peft.__version__}")
```

## üèãÔ∏è –û–±—É—á–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

### –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
```bash
python train_debug_2.py \
  --model_name "Qwen/Qwen2.5-1.5B" \
  --data_path "./data/dnd_dataset.jsonl" \
  --output_dir "./models/my-dnd-assistant" \
  --use_lora \
  --lora_r 16 \
  --lora_alpha 64 \
  --lora_dropout 0.1 \
  --per_device_train_batch_size 4 \
  --num_train_epochs 3 \
  --learning_rate 2e-4 \
  --max_length 512 \
  --logging_steps 10 \
  --eval_steps 100 \
  --save_steps 200 \
  --test_size 0.1 \
  --seed 6959
```

### –û–±—É—á–µ–Ω–∏–µ –Ω–∞ Google Colab
```python
# –í —è—á–µ–π–∫–µ Colab
!pip install -q transformers datasets peft accelerate torch

!wget https://huggingface.co/datasets/m0no1/dnd-mechanics-dataset/resolve/main/train.jsonl -O dnd_dataset.jsonl

!python train_debug_2.py \
  --model_name "Qwen/Qwen2.5-1.5B" \
  --data_path "dnd_dataset.jsonl" \
  --output_dir "/content/dnd-lora-model" \
  --use_lora \
  --lora_r 16 \
  --per_device_train_batch_size 2 \
  --gradient_accumulation_steps 4 \
  --num_train_epochs 3 \
  --learning_rate 2e-4 \
  --max_length 512 \
  --save_to_drive
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è
–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –≤—ã –º–æ–∂–µ—Ç–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å:

1. **–í –∫–æ–Ω—Å–æ–ª–∏**: –î–µ—Ç–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤
2. **TensorBoard**: 
   ```bash
   tensorboard --logdir ./logs
   ```
3. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏**: –°–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫–µ logs/
4. **–ú–µ—Ç—Ä–∏–∫–∏ –≤ JSON**: –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

## üéÆ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

### –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
```bash
# –ó–∞–ø—É—Å–∫ —á–∞—Ç-—Ä–µ–∂–∏–º–∞
python chatting.py --model_name "Qwen/Qwen2.5-1.5B" --model_dir "./my-lora-model"

# –° —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
python chatting.py \
  --model_name "Qwen/Qwen2.5-1.5B" \
  --model_dir "./my-lora-model" \
  --test_seed 6758
```

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
```python
from transformers import pipeline

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
dnd_assistant = pipeline(
    "text-generation",
    model="Qwen/Qwen2.5-1.5B",
    peft_model="./my-lora-model",
    device=0 if torch.cuda.is_available() else -1
)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
response = dnd_assistant(
    "How do I calculate attack bonus for a level 5 fighter?",
    max_length=150,
    temperature=0.7,
    do_sample=True
)
print(response[0]['generated_text'])
```

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

### –ö–∞—Ä—Ç–æ—á–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
- **–ù–∞–∑–≤–∞–Ω–∏–µ**: Qwen2.5-1.5B
- **–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫**: Alibaba Cloud
- **–Ø–∑—ã–∫–∏**: –ê–Ω–≥–ª–∏–π—Å–∫–∏–π, –∫–∏—Ç–∞–π—Å–∫–∏–π
- **–õ–∏—Ü–µ–Ω–∑–∏—è**: Tongyi Qianwen LICENSE
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –î–µ–∫–æ–¥–µ—Ä-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä
- **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**: 1.5 –º–∏–ª–ª–∏–∞—Ä–¥–∞

### –ö–∞—Ä—Ç–æ—á–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
- **–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å**: Qwen2.5-1.5B
- **–ú–µ—Ç–æ–¥ –¥–æ–æ–±—É—á–µ–Ω–∏—è**: LoRA (Low-Rank Adaptation)
- **–î–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è**: D&D 3.5 Mechanics Dataset
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è**: –ü—Ä–∞–≤–∏–ª–∞ –∏ –º–µ—Ö–∞–Ω–∏–∫–∏ D&D 3.5
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: –ü–æ–º–æ—â—å –ú–∞—Å—Ç–µ—Ä—É –ü–æ–¥–∑–µ–º–µ–ª–∏–π, –∏–≥—Ä–æ–∫–∞–º
- **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è**: –ó–Ω–∞–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –ø—Ä–∞–≤–∏–ª–∞–º–∏ D&D 3.5

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–¥–º–æ–¥—É–ª—è–º–∏
git clone --recurse-submodules https://github.com/Xiaiur/LLM_dnd35.git

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
pip install -r requirements.txt

```

## üìñ –†–µ—Å—É—Ä—Å—ã –∏ —Å—Å—ã–ª–∫–∏

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è PEFT](https://huggingface.co/docs/peft)
- [–ö–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏ Qwen2.5](https://huggingface.co/Qwen/Qwen2.5-1.5B)
- [–î–∞—Ç–∞—Å–µ—Ç D&D 3.5 Mechanics](https://huggingface.co/datasets/m0no1/dnd-mechanics-dataset)
```

**–£–¥–∞—á–Ω—ã—Ö –ø—Ä–∏–∫–ª—é—á–µ–Ω–∏–π! –ü—É—Å—Ç—å –≤–∞—à–∏ –±—Ä–æ—Å–∫–∏ –±—É–¥—É—Ç –Ω–∞—Ç—É—Ä–∞–ª—å–Ω—ã–º–∏ 20!** üé≤‚ú®

*"–ú–∞—Å—Ç–µ—Ä –ü–æ–¥–∑–µ–º–µ–ª–∏–π –≤—Å–µ–≥–¥–∞ –Ω–∞ —Å–≤—è–∑–∏, —Ç–µ–ø–µ—Ä—å —Å –ò–ò-–ø–æ–º–æ—â–Ω–∏–∫–æ–º!"* üßô‚Äç‚ôÇÔ∏èüîÆ
